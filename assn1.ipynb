{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# load MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAD8CAYAAAABraMFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5kdETmLzIyIn/R+KxB3xQTzcVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3031766550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#flatten 28*28 images\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define baseline model\n",
    "def baseline_model():\n",
    "\tseed = 7\n",
    "\tnumpy.random.seed(seed)\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(500, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(300, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(200, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error: 1.46%\n",
      "Accuracy: 98.54%\n",
      "What is this??: 13.33%\n"
     ]
    }
   ],
   "source": [
    "# run this cell to load the trained model\n",
    "model1= load_model('hidden_5_500_300_300_200_adam_relu100ep.hdf5')\n",
    "scores = model1.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 1,310,750\n",
      "Trainable params: 1,310,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "Epoch 00000: val_acc improved from -inf to 0.96275, saving model to check.hdf5\n",
      "22s - loss: 0.2590 - acc: 0.9212 - val_loss: 0.1212 - val_acc: 0.9627\n",
      "Epoch 2/100\n",
      "Epoch 00001: val_acc improved from 0.96275 to 0.96858, saving model to check.hdf5\n",
      "20s - loss: 0.0961 - acc: 0.9702 - val_loss: 0.1022 - val_acc: 0.9686\n",
      "Epoch 3/100\n",
      "Epoch 00002: val_acc improved from 0.96858 to 0.97042, saving model to check.hdf5\n",
      "20s - loss: 0.0631 - acc: 0.9807 - val_loss: 0.0980 - val_acc: 0.9704\n",
      "Epoch 4/100\n",
      "Epoch 00003: val_acc did not improve\n",
      "20s - loss: 0.0479 - acc: 0.9854 - val_loss: 0.1206 - val_acc: 0.9696\n",
      "Epoch 5/100\n",
      "Epoch 00004: val_acc improved from 0.97042 to 0.97542, saving model to check.hdf5\n",
      "20s - loss: 0.0399 - acc: 0.9874 - val_loss: 0.0883 - val_acc: 0.9754\n",
      "Epoch 6/100\n",
      "Epoch 00005: val_acc did not improve\n",
      "20s - loss: 0.0347 - acc: 0.9899 - val_loss: 0.1116 - val_acc: 0.9714\n",
      "Epoch 7/100\n",
      "Epoch 00006: val_acc improved from 0.97542 to 0.97783, saving model to check.hdf5\n",
      "20s - loss: 0.0294 - acc: 0.9910 - val_loss: 0.0969 - val_acc: 0.9778\n",
      "Epoch 8/100\n",
      "Epoch 00007: val_acc did not improve\n",
      "20s - loss: 0.0269 - acc: 0.9920 - val_loss: 0.1019 - val_acc: 0.9749\n",
      "Epoch 9/100\n",
      "Epoch 00008: val_acc did not improve\n",
      "20s - loss: 0.0202 - acc: 0.9939 - val_loss: 0.1198 - val_acc: 0.9745\n",
      "Epoch 10/100\n",
      "Epoch 00009: val_acc did not improve\n",
      "20s - loss: 0.0284 - acc: 0.9919 - val_loss: 0.1076 - val_acc: 0.9739\n",
      "Epoch 11/100\n",
      "Epoch 00010: val_acc improved from 0.97783 to 0.97925, saving model to check.hdf5\n",
      "20s - loss: 0.0190 - acc: 0.9943 - val_loss: 0.0926 - val_acc: 0.9792\n",
      "Epoch 12/100\n",
      "Epoch 00011: val_acc did not improve\n",
      "20s - loss: 0.0152 - acc: 0.9954 - val_loss: 0.1125 - val_acc: 0.9768\n",
      "Epoch 13/100\n",
      "Epoch 00012: val_acc did not improve\n",
      "20s - loss: 0.0167 - acc: 0.9949 - val_loss: 0.1342 - val_acc: 0.9742\n",
      "Epoch 14/100\n",
      "Epoch 00013: val_acc did not improve\n",
      "20s - loss: 0.0119 - acc: 0.9965 - val_loss: 0.1189 - val_acc: 0.9788\n",
      "Epoch 15/100\n",
      "Epoch 00014: val_acc did not improve\n",
      "20s - loss: 0.0153 - acc: 0.9955 - val_loss: 0.1256 - val_acc: 0.9781\n",
      "Epoch 16/100\n",
      "Epoch 00015: val_acc did not improve\n",
      "20s - loss: 0.0154 - acc: 0.9957 - val_loss: 0.1225 - val_acc: 0.9783\n",
      "Epoch 17/100\n",
      "Epoch 00016: val_acc did not improve\n",
      "21s - loss: 0.0158 - acc: 0.9960 - val_loss: 0.1288 - val_acc: 0.9767\n",
      "Epoch 18/100\n",
      "Epoch 00017: val_acc did not improve\n",
      "20s - loss: 0.0104 - acc: 0.9970 - val_loss: 0.1350 - val_acc: 0.9768\n",
      "Epoch 19/100\n",
      "Epoch 00018: val_acc did not improve\n",
      "20s - loss: 0.0133 - acc: 0.9962 - val_loss: 0.1262 - val_acc: 0.9784\n",
      "Epoch 20/100\n",
      "Epoch 00019: val_acc improved from 0.97925 to 0.97983, saving model to check.hdf5\n",
      "22s - loss: 0.0114 - acc: 0.9968 - val_loss: 0.1141 - val_acc: 0.9798\n",
      "Epoch 21/100\n",
      "Epoch 00020: val_acc did not improve\n",
      "21s - loss: 0.0115 - acc: 0.9967 - val_loss: 0.1252 - val_acc: 0.9793\n",
      "Epoch 22/100\n",
      "Epoch 00021: val_acc did not improve\n",
      "20s - loss: 0.0184 - acc: 0.9962 - val_loss: 0.1229 - val_acc: 0.9782\n",
      "Epoch 23/100\n",
      "Epoch 00022: val_acc improved from 0.97983 to 0.98000, saving model to check.hdf5\n",
      "20s - loss: 0.0148 - acc: 0.9965 - val_loss: 0.1020 - val_acc: 0.9800\n",
      "Epoch 24/100\n",
      "Epoch 00023: val_acc improved from 0.98000 to 0.98158, saving model to check.hdf5\n",
      "20s - loss: 0.0112 - acc: 0.9975 - val_loss: 0.1003 - val_acc: 0.9816\n",
      "Epoch 25/100\n",
      "Epoch 00024: val_acc did not improve\n",
      "20s - loss: 0.0087 - acc: 0.9979 - val_loss: 0.1481 - val_acc: 0.9769\n",
      "Epoch 26/100\n",
      "Epoch 00025: val_acc did not improve\n",
      "20s - loss: 0.0122 - acc: 0.9969 - val_loss: 0.1149 - val_acc: 0.9794\n",
      "Epoch 27/100\n",
      "Epoch 00026: val_acc did not improve\n",
      "20s - loss: 0.0074 - acc: 0.9983 - val_loss: 0.1324 - val_acc: 0.9777\n",
      "Epoch 28/100\n",
      "Epoch 00027: val_acc did not improve\n",
      "20s - loss: 0.0089 - acc: 0.9976 - val_loss: 0.1223 - val_acc: 0.9803\n",
      "Epoch 29/100\n",
      "Epoch 00028: val_acc did not improve\n",
      "21s - loss: 0.0098 - acc: 0.9979 - val_loss: 0.1116 - val_acc: 0.9794\n",
      "Epoch 30/100\n",
      "Epoch 00029: val_acc did not improve\n",
      "20s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.1421 - val_acc: 0.9796\n",
      "Epoch 31/100\n",
      "Epoch 00030: val_acc did not improve\n",
      "20s - loss: 0.0064 - acc: 0.9982 - val_loss: 0.1409 - val_acc: 0.9807\n",
      "Epoch 32/100\n",
      "Epoch 00031: val_acc improved from 0.98158 to 0.98217, saving model to check.hdf5\n",
      "20s - loss: 0.0123 - acc: 0.9974 - val_loss: 0.1153 - val_acc: 0.9822\n",
      "Epoch 33/100\n",
      "Epoch 00032: val_acc did not improve\n",
      "20s - loss: 0.0086 - acc: 0.9979 - val_loss: 0.1374 - val_acc: 0.9790\n",
      "Epoch 34/100\n",
      "Epoch 00033: val_acc did not improve\n",
      "20s - loss: 0.0085 - acc: 0.9979 - val_loss: 0.1163 - val_acc: 0.9801\n",
      "Epoch 35/100\n",
      "Epoch 00034: val_acc did not improve\n",
      "20s - loss: 0.0072 - acc: 0.9981 - val_loss: 0.1225 - val_acc: 0.9813\n",
      "Epoch 36/100\n",
      "Epoch 00035: val_acc did not improve\n",
      "20s - loss: 0.0067 - acc: 0.9986 - val_loss: 0.1449 - val_acc: 0.9787\n",
      "Epoch 37/100\n",
      "Epoch 00036: val_acc did not improve\n",
      "20s - loss: 0.0125 - acc: 0.9968 - val_loss: 0.1271 - val_acc: 0.9782\n",
      "Epoch 38/100\n",
      "Epoch 00037: val_acc did not improve\n",
      "20s - loss: 0.0050 - acc: 0.9988 - val_loss: 0.1240 - val_acc: 0.9820\n",
      "Epoch 39/100\n",
      "Epoch 00038: val_acc did not improve\n",
      "20s - loss: 0.0063 - acc: 0.9987 - val_loss: 0.1348 - val_acc: 0.9772\n",
      "Epoch 40/100\n",
      "Epoch 00039: val_acc did not improve\n",
      "20s - loss: 0.0070 - acc: 0.9985 - val_loss: 0.1395 - val_acc: 0.9786\n",
      "Epoch 41/100\n",
      "Epoch 00040: val_acc did not improve\n",
      "20s - loss: 0.0093 - acc: 0.9978 - val_loss: 0.1240 - val_acc: 0.9791\n",
      "Epoch 42/100\n",
      "Epoch 00041: val_acc did not improve\n",
      "20s - loss: 0.0080 - acc: 0.9983 - val_loss: 0.1668 - val_acc: 0.9747\n",
      "Epoch 43/100\n",
      "Epoch 00042: val_acc improved from 0.98217 to 0.98225, saving model to check.hdf5\n",
      "20s - loss: 0.0071 - acc: 0.9981 - val_loss: 0.1175 - val_acc: 0.9822\n",
      "Epoch 44/100\n",
      "Epoch 00043: val_acc did not improve\n",
      "20s - loss: 0.0092 - acc: 0.9978 - val_loss: 0.1386 - val_acc: 0.9815\n",
      "Epoch 45/100\n",
      "Epoch 00044: val_acc did not improve\n",
      "20s - loss: 0.0034 - acc: 0.9991 - val_loss: 0.1456 - val_acc: 0.9799\n",
      "Epoch 46/100\n",
      "Epoch 00045: val_acc did not improve\n",
      "20s - loss: 0.0062 - acc: 0.9986 - val_loss: 0.1359 - val_acc: 0.9787\n",
      "Epoch 47/100\n",
      "Epoch 00046: val_acc did not improve\n",
      "21s - loss: 0.0062 - acc: 0.9985 - val_loss: 0.1303 - val_acc: 0.9820\n",
      "Epoch 48/100\n",
      "Epoch 00047: val_acc did not improve\n",
      "20s - loss: 0.0078 - acc: 0.9980 - val_loss: 0.1201 - val_acc: 0.9807\n",
      "Epoch 49/100\n",
      "Epoch 00048: val_acc did not improve\n",
      "20s - loss: 0.0067 - acc: 0.9985 - val_loss: 0.1454 - val_acc: 0.9807\n",
      "Epoch 50/100\n",
      "Epoch 00049: val_acc improved from 0.98225 to 0.98292, saving model to check.hdf5\n",
      "20s - loss: 0.0041 - acc: 0.9992 - val_loss: 0.1360 - val_acc: 0.9829\n",
      "Epoch 51/100\n",
      "Epoch 00050: val_acc did not improve\n",
      "20s - loss: 0.0015 - acc: 0.9996 - val_loss: 0.1375 - val_acc: 0.9820\n",
      "Epoch 52/100\n",
      "Epoch 00051: val_acc did not improve\n",
      "20s - loss: 0.0040 - acc: 0.9992 - val_loss: 0.1437 - val_acc: 0.9781\n",
      "Epoch 53/100\n",
      "Epoch 00052: val_acc did not improve\n",
      "20s - loss: 0.0090 - acc: 0.9980 - val_loss: 0.1414 - val_acc: 0.9816\n",
      "Epoch 54/100\n",
      "Epoch 00053: val_acc did not improve\n",
      "21s - loss: 0.0137 - acc: 0.9970 - val_loss: 0.1038 - val_acc: 0.9807\n",
      "Epoch 55/100\n",
      "Epoch 00054: val_acc did not improve\n",
      "20s - loss: 0.0067 - acc: 0.9985 - val_loss: 0.1313 - val_acc: 0.9802\n",
      "Epoch 56/100\n",
      "Epoch 00055: val_acc did not improve\n",
      "20s - loss: 0.0056 - acc: 0.9987 - val_loss: 0.1250 - val_acc: 0.9809\n",
      "Epoch 57/100\n",
      "Epoch 00056: val_acc did not improve\n",
      "20s - loss: 0.0056 - acc: 0.9988 - val_loss: 0.1545 - val_acc: 0.9807\n",
      "Epoch 58/100\n",
      "Epoch 00057: val_acc did not improve\n",
      "20s - loss: 0.0076 - acc: 0.9982 - val_loss: 0.1575 - val_acc: 0.9815\n",
      "Epoch 59/100\n",
      "Epoch 00058: val_acc did not improve\n",
      "20s - loss: 0.0059 - acc: 0.9988 - val_loss: 0.1251 - val_acc: 0.9828\n",
      "Epoch 60/100\n",
      "Epoch 00059: val_acc did not improve\n",
      "21s - loss: 0.0030 - acc: 0.9994 - val_loss: 0.1638 - val_acc: 0.9802\n",
      "Epoch 61/100\n",
      "Epoch 00060: val_acc did not improve\n",
      "20s - loss: 0.0079 - acc: 0.9984 - val_loss: 0.1406 - val_acc: 0.9818\n",
      "Epoch 62/100\n",
      "Epoch 00061: val_acc did not improve\n",
      "20s - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1790 - val_acc: 0.9805\n",
      "Epoch 63/100\n",
      "Epoch 00062: val_acc did not improve\n",
      "21s - loss: 0.0070 - acc: 0.9988 - val_loss: 0.1294 - val_acc: 0.9805\n",
      "Epoch 64/100\n",
      "Epoch 00063: val_acc did not improve\n",
      "20s - loss: 0.0104 - acc: 0.9981 - val_loss: 0.1656 - val_acc: 0.9791\n",
      "Epoch 65/100\n",
      "Epoch 00064: val_acc did not improve\n",
      "20s - loss: 0.0091 - acc: 0.9981 - val_loss: 0.1271 - val_acc: 0.9818\n",
      "Epoch 66/100\n",
      "Epoch 00065: val_acc did not improve\n",
      "20s - loss: 0.0084 - acc: 0.9986 - val_loss: 0.1396 - val_acc: 0.9792\n",
      "Epoch 67/100\n",
      "Epoch 00066: val_acc did not improve\n",
      "20s - loss: 0.0101 - acc: 0.9980 - val_loss: 0.1337 - val_acc: 0.9809\n",
      "Epoch 68/100\n",
      "Epoch 00067: val_acc did not improve\n",
      "20s - loss: 0.0060 - acc: 0.9988 - val_loss: 0.1474 - val_acc: 0.9799\n",
      "Epoch 69/100\n",
      "Epoch 00068: val_acc did not improve\n",
      "20s - loss: 0.0011 - acc: 0.9997 - val_loss: 0.1579 - val_acc: 0.9819\n",
      "Epoch 70/100\n",
      "Epoch 00069: val_acc did not improve\n",
      "20s - loss: 0.0024 - acc: 0.9994 - val_loss: 0.1476 - val_acc: 0.9794\n",
      "Epoch 71/100\n",
      "Epoch 00070: val_acc did not improve\n",
      "20s - loss: 0.0050 - acc: 0.9988 - val_loss: 0.1236 - val_acc: 0.9813\n",
      "Epoch 72/100\n",
      "Epoch 00071: val_acc did not improve\n",
      "20s - loss: 0.0100 - acc: 0.9982 - val_loss: 0.1460 - val_acc: 0.9824\n",
      "Epoch 73/100\n",
      "Epoch 00072: val_acc did not improve\n",
      "20s - loss: 0.0082 - acc: 0.9984 - val_loss: 0.1530 - val_acc: 0.9795\n",
      "Epoch 74/100\n",
      "Epoch 00073: val_acc did not improve\n",
      "20s - loss: 0.0117 - acc: 0.9981 - val_loss: 0.1537 - val_acc: 0.9784\n",
      "Epoch 75/100\n",
      "Epoch 00074: val_acc did not improve\n",
      "20s - loss: 0.0040 - acc: 0.9990 - val_loss: 0.1738 - val_acc: 0.9789\n",
      "Epoch 76/100\n",
      "Epoch 00075: val_acc did not improve\n",
      "20s - loss: 0.0088 - acc: 0.9983 - val_loss: 0.1484 - val_acc: 0.9804\n",
      "Epoch 77/100\n",
      "Epoch 00076: val_acc did not improve\n",
      "20s - loss: 0.0090 - acc: 0.9987 - val_loss: 0.1949 - val_acc: 0.9775\n",
      "Epoch 78/100\n",
      "Epoch 00077: val_acc did not improve\n",
      "20s - loss: 0.0143 - acc: 0.9975 - val_loss: 0.1266 - val_acc: 0.9815\n",
      "Epoch 79/100\n",
      "Epoch 00078: val_acc did not improve\n",
      "20s - loss: 0.0017 - acc: 0.9996 - val_loss: 0.1254 - val_acc: 0.9827\n",
      "Epoch 80/100\n",
      "Epoch 00079: val_acc did not improve\n",
      "20s - loss: 9.4785e-04 - acc: 0.9998 - val_loss: 0.1367 - val_acc: 0.9817\n",
      "Epoch 81/100\n",
      "Epoch 00080: val_acc did not improve\n",
      "20s - loss: 0.0012 - acc: 0.9998 - val_loss: 0.1796 - val_acc: 0.9803\n",
      "Epoch 82/100\n",
      "Epoch 00081: val_acc did not improve\n",
      "23s - loss: 0.0133 - acc: 0.9978 - val_loss: 0.1507 - val_acc: 0.9789\n",
      "Epoch 83/100\n",
      "Epoch 00082: val_acc did not improve\n",
      "20s - loss: 0.0064 - acc: 0.9987 - val_loss: 0.1471 - val_acc: 0.9802\n",
      "Epoch 84/100\n",
      "Epoch 00083: val_acc did not improve\n",
      "20s - loss: 0.0053 - acc: 0.9991 - val_loss: 0.1516 - val_acc: 0.9795\n",
      "Epoch 85/100\n",
      "Epoch 00084: val_acc did not improve\n",
      "20s - loss: 0.0100 - acc: 0.9983 - val_loss: 0.1628 - val_acc: 0.9797\n",
      "Epoch 86/100\n",
      "Epoch 00085: val_acc did not improve\n",
      "20s - loss: 0.0058 - acc: 0.9987 - val_loss: 0.1498 - val_acc: 0.9817\n",
      "Epoch 87/100\n",
      "Epoch 00086: val_acc did not improve\n",
      "20s - loss: 0.0032 - acc: 0.9993 - val_loss: 0.1447 - val_acc: 0.9802\n",
      "Epoch 88/100\n",
      "Epoch 00087: val_acc improved from 0.98292 to 0.98333, saving model to check.hdf5\n",
      "20s - loss: 0.0019 - acc: 0.9995 - val_loss: 0.1464 - val_acc: 0.9833\n",
      "Epoch 89/100\n",
      "Epoch 00088: val_acc did not improve\n",
      "20s - loss: 0.0034 - acc: 0.9993 - val_loss: 0.1443 - val_acc: 0.9824\n",
      "Epoch 90/100\n",
      "Epoch 00089: val_acc did not improve\n",
      "20s - loss: 0.0014 - acc: 0.9997 - val_loss: 0.1623 - val_acc: 0.9810\n",
      "Epoch 91/100\n",
      "Epoch 00090: val_acc did not improve\n",
      "20s - loss: 0.0100 - acc: 0.9983 - val_loss: 0.1340 - val_acc: 0.9817\n",
      "Epoch 92/100\n",
      "Epoch 00091: val_acc did not improve\n",
      "20s - loss: 0.0030 - acc: 0.9992 - val_loss: 0.1510 - val_acc: 0.9829\n",
      "Epoch 93/100\n",
      "Epoch 00092: val_acc did not improve\n",
      "20s - loss: 0.0045 - acc: 0.9993 - val_loss: 0.1730 - val_acc: 0.9816\n",
      "Epoch 94/100\n",
      "Epoch 00093: val_acc did not improve\n",
      "20s - loss: 0.0127 - acc: 0.9978 - val_loss: 0.1897 - val_acc: 0.9758\n",
      "Epoch 95/100\n",
      "Epoch 00094: val_acc did not improve\n",
      "20s - loss: 0.0078 - acc: 0.9984 - val_loss: 0.1400 - val_acc: 0.9831\n",
      "Epoch 96/100\n",
      "Epoch 00095: val_acc did not improve\n",
      "20s - loss: 0.0064 - acc: 0.9991 - val_loss: 0.1333 - val_acc: 0.9817\n",
      "Epoch 97/100\n",
      "Epoch 00096: val_acc did not improve\n",
      "20s - loss: 0.0079 - acc: 0.9989 - val_loss: 0.1602 - val_acc: 0.9810\n",
      "Epoch 98/100\n",
      "Epoch 00097: val_acc did not improve\n",
      "20s - loss: 0.0040 - acc: 0.9992 - val_loss: 0.1414 - val_acc: 0.9828\n",
      "Epoch 99/100\n",
      "Epoch 00098: val_acc did not improve\n",
      "20s - loss: 0.0016 - acc: 0.9996 - val_loss: 0.1621 - val_acc: 0.9795\n",
      "Epoch 100/100\n",
      "Epoch 00099: val_acc did not improve\n",
      "20s - loss: 0.0037 - acc: 0.9992 - val_loss: 0.1515 - val_acc: 0.9811\n",
      "Baseline Error: 1.63%\n",
      "Accuracy: 98.37%\n"
     ]
    }
   ],
   "source": [
    "# run this cell to train the model from the beginning\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "print(model.summary())\n",
    "checkpoint = ModelCheckpoint('check.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "# Fit the model\n",
    "history =model.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=128, callbacks=callbacks_list, verbose=2)\n",
    "# Final evaluation of the model\n",
    "model= load_model('check.hdf5')\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
